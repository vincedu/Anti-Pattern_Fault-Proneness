{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c44d93f",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "delete files in manually labeled data (**release-level-data** from replication kit https://zenodo.org/record/5675024#.Ya-B8fHML0o) that are not related to bug fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96b147ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data cleaning done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for filename in os.listdir('./release-level-data'):\n",
    "    if filename.endswith(\"bug_fixes.json\"):\n",
    "        continue\n",
    "    os.remove('./release-level-data/' + filename)\n",
    "print(\"data cleaning done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aa4412",
   "metadata": {},
   "source": [
    "# Extract traditional smells\n",
    "returns a dictionary of list, with key represents a traditional smell and value represents list of classes that contain the smell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89da67f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "import sys\n",
    "\n",
    "def extract_traditional_smells(project_name):\n",
    "    print(\"extracting traditional smells from repository: \" + project_name)\n",
    "    subprocess.call(['java', '-jar', './DECOR_JAVA.jar', project_name, project_name, \"\"])\n",
    "\n",
    "    # check if the result of detection is generated\n",
    "    if os.path.isdir('../TEMP'):\n",
    "\n",
    "        # dictionary of list, key represents a traditional smell and value represents list of classes that contain the smell\n",
    "        smell_classes_dict = {}\n",
    "        # iterate through each generated file\n",
    "        result_files_path = \"../TEMP/\" + project_name\n",
    "        for filename in os.listdir(result_files_path):\n",
    "\n",
    "            # read the content of the file\n",
    "            file_path = result_files_path + \"/\" + filename\n",
    "            with open(file_path) as file:\n",
    "                file_content = '[dummy_section]\\n' + file.read()\n",
    "            config = configparser.ConfigParser()\n",
    "            config.read_string(file_content)\n",
    "\n",
    "            # find all smelly test classes that contain traditional smell\n",
    "            smelly_classes = []\n",
    "            for key, value in config.items('dummy_section'):\n",
    "                if re.match(\"^[0-9]+\\.[0-9]+\\.[a-zA-Z]+-\\d$\", key):\n",
    "                    class_name = value.split(\".\")[-1]\n",
    "                    smelly_classes.append(class_name)\n",
    "            # map smell and classes containing the smell\n",
    "            if smelly_classes:\n",
    "                smell_name = filename.split(\" \")[-1].split(\".\")[0]\n",
    "                smell_classes_dict[smell_name] = smelly_classes\n",
    "\n",
    "        # delete result of detection\n",
    "        try:\n",
    "            shutil.rmtree(\"../TEMP/\")\n",
    "        except OSError as e:\n",
    "            print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "        finally:\n",
    "            print(\"Traditional smells extracted for project: \", project_name)\n",
    "            return smell_classes_dict\n",
    "\n",
    "    else:    \n",
    "        print(\"ERROR: extracting traditionial smells failed\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a67a00",
   "metadata": {},
   "source": [
    "# Extract traditional smells test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c3d0d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting traditional smells from repository: ant-ivy\n",
      "Traditional smells extracted for project:  ant-ivy\n",
      "{'LazyClass': ['IvyWebdavFileSystem', 'IvyWebdavFileSystem'], 'LongMethod': ['VfsResourceTest', 'XmlModuleUpdaterTest', 'IvyCachePathTest', 'TestPerformance', 'IvyCacheTask', 'ModuleRevisionId', 'IvyVar', 'ResolveTest', 'CredentialsUtil', 'IBiblioResolverTest', 'SortTest', 'IvyArtifactReport', 'IvyInstall', 'VfsRepository', 'IvyTask', 'JarJarDependencyAnalyser', 'IvyWebdavClientFactory', 'VersionRangeMatcher', 'FileUtil', 'MRIDTransformationRuleTest', 'AbstractSshBasedRepository', 'SshRepository', 'Main', 'AntBuildTrigger', 'IvyReport', 'IvyBuildNumber', 'IvyCacheFileset', 'DualResolverTest', 'IvyPublishTest', 'ConfiguratorTest', 'IvyWebdavConnectionManager', 'ApacheURLLister', 'Message', 'JarModuleFinder', 'ChainResolverTest', 'IvyConfigure', 'DefaultModuleDescriptor', 'RepositoryResolver', 'IvyListModules', 'IvyInfo', 'SFTPRepository', 'VfsRepositoryTest', 'BasicURLHandler', 'IBiblioHelper', 'ResolverHelper', 'IvyBuildListTest', 'IvyArtifactProperty', 'AntCallTriggerTest', 'ModuleDescriptorSorter', 'IvyEventFilter', 'PomModuleDescriptorParserTest', 'AntCallTrigger', 'IvyPostResolveTask', 'IvyCheck', 'SshCache', 'IvyRepResolverTest', 'IvyRetrieveTest', 'IvyExtractFromSources', 'URLRepository', 'IvyRepositoryReport', 'URLResolverTest', 'ResolveReport', 'HttpClientHandler', 'ConfigurationsExample', 'IvyDeliverTest', 'DefaultDependencyDescriptor', 'CacheResolver'], 'ClassDataShouldBePrivate': ['LatestRevisionStrategy', 'FilterHelper', 'XmlModuleDescriptorUpdater', 'VfsTestHelper'], 'ComplexClass': ['IvyPatternHelper', 'VfsURI', 'AbstractResolver', 'IvyPatternHelper', 'Scp', 'SFTPRepository', 'TransferEvent', 'IvyResolve', 'XmlReportOutputter', 'IvyReport', 'IvyPublish', 'XmlModuleDescriptorParser', 'IvyBuildList', 'IvyDeliver', 'PomModuleDescriptorParser', 'IvyPostResolveTask', 'IvyResolve', 'IvyNode', 'IvyBuildList', 'Ivy', 'AbstractModuleDescriptorParser', 'VersionRangeMatcher', 'IvyBuildNumber', 'IvyPublish', 'SshRepository', 'Configuration', 'IvyPostResolveTask', 'ResolveTest', 'StatusManager', 'ConfigurationResolveReport', 'IvyArtifactReport', 'RepositoryResolver', 'SshCache', 'DefaultDependencyDescriptor', 'IvyTask', 'BasicResolver', 'BasicURLHandler', 'IvyReport', 'VfsResourceTest', 'XmlModuleDescriptorWriter', 'AbstractResolver', 'Configurator', 'IvyDeliver', 'Ivy', 'IBiblioResolver', 'CredentialsUtil', 'AbstractResourceResolver', 'BasicResolver', 'DefaultModuleDescriptor', 'IvyRepResolver', 'IvyNode', 'DefaultDependencyDescriptor', 'VsftpRepository', 'DefaultModuleDescriptor', 'IvyRepositoryReport', 'FileUtil', 'VfsRepositoryTest', 'XmlIvyConfigurationParser', 'Main', 'TransferEvent', 'HttpClientHandler', 'ResolverHelper', 'Message', 'AbstractSshBasedRepository', 'VsftpRepository', 'ChainResolver'], 'AntiSingleton': ['XmlModuleDescriptorUpdater', 'FilterHelper'], 'LongParameterList': ['BasicResource', 'TransferEvent', 'IvyReport', 'VfsURI', 'DefaultDependencyArtifactDescriptor', 'SshResource', 'IvyPatternHelper', 'MockResolver', 'IvyTask', 'Configuration', 'Ivy', 'MDArtifact', 'DefaultDependencyDescriptor', 'SshCache', 'EndArtifactDownloadEvent', 'IvyNode', 'AbstractModuleDescriptorParserTester', 'ConfigurationResolveReport', 'DefaultModuleRevision', 'ResolveData', 'IvyWebdavClientFactory', 'ArtifactRevisionId', 'Main', 'DefaultArtifact', 'ModuleRevisionId', 'IvyRepositoryReport', 'XmlModuleDescriptorUpdater', 'RepositoryResolver', 'AbstractResourceResolver', 'TestPerformance', 'ResolveTest']}\n"
     ]
    }
   ],
   "source": [
    "smell_classes_dict = extract_traditional_smells('ant-ivy')\n",
    "print(smell_classes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6464f9ff",
   "metadata": {},
   "source": [
    "# Extract traditional smells 2\n",
    "returns a set of classes that contain a smell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "23bac299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "import sys\n",
    "\n",
    "def extract_traditional_smells2(project_name):\n",
    "    print(\"extracting traditional smells from repository: \" + project_name)\n",
    "    subprocess.call(['java', '-jar', './DECOR_JAVA.jar', project_name, project_name, \"\"])\n",
    "\n",
    "    # check if the result of detection is generated\n",
    "    if os.path.isdir('../TEMP'):\n",
    "\n",
    "        # set of classes that contain the smell\n",
    "        smell_classes_set = set()\n",
    "\n",
    "        # iterate through each generated file\n",
    "        result_files_path = \"../TEMP/\" + project_name\n",
    "        for filename in os.listdir(result_files_path):\n",
    "\n",
    "            # read the content of the file\n",
    "            file_path = result_files_path + \"/\" + filename\n",
    "            with open(file_path) as file:\n",
    "                file_content = '[dummy_section]\\n' + file.read()\n",
    "            config = configparser.ConfigParser()\n",
    "            config.read_string(file_content)\n",
    "\n",
    "            # find all smelly test classes that contain traditional smell\n",
    "            for key, value in config.items('dummy_section'):\n",
    "                if re.match(\"^[0-9]+\\.[0-9]+\\.[a-zA-Z]+-\\d$\", key):\n",
    "                    class_name = value.split(\".\")[-1]\n",
    "                    smell_classes_set.add(class_name)\n",
    "\n",
    "        # delete result of detection\n",
    "        try:\n",
    "            shutil.rmtree(\"../TEMP/\")\n",
    "        except OSError as e:\n",
    "            print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "        finally:\n",
    "            print(\"Traditional smells extracted for project: \", project_name)\n",
    "            return smell_classes_set\n",
    "\n",
    "    else:    \n",
    "        print(\"ERROR: extracting traditionial smells failed\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e284a6d5",
   "metadata": {},
   "source": [
    "# OpenSZZ\n",
    "run OpenSZZ on releases of selected projects, extract bug fixing files, and save them as JSON file in the same format as manual validated data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d7e5721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting bug fixing files using OpenSZZ from repository: ant-ivy at release 1.4.1\n",
      "extraction done\n",
      "release level data generated with OpenSZZ for projectant-ivy at release 1.4.1\n",
      "extracting bug fixing files using OpenSZZ from repository: ant-ivy at release 2.0.0\n",
      "extraction done\n",
      "release level data generated with OpenSZZ for projectant-ivy at release 2.0.0\n",
      "extracting bug fixing files using OpenSZZ from repository: ant-ivy at release 2.1.0\n",
      "extraction done\n",
      "release level data generated with OpenSZZ for projectant-ivy at release 2.1.0\n",
      "extracting bug fixing files using OpenSZZ from repository: ant-ivy at release 2.2.0\n",
      "extraction done\n",
      "release level data generated with OpenSZZ for projectant-ivy at release 2.2.0\n",
      "extracting bug fixing files using OpenSZZ from repository: ant-ivy at release 2.3.0\n",
      "extraction done\n",
      "release level data generated with OpenSZZ for projectant-ivy at release 2.3.0\n",
      "extracting bug fixing files using OpenSZZ from repository: ant-ivy at release 2.4.0\n",
      "extraction done\n",
      "release level data generated with OpenSZZ for projectant-ivy at release 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from git import Repo\n",
    "import subprocess\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# os.mkdir('release-level-data-OpenSZZ')\n",
    "\n",
    "df = pd.read_csv('projects.csv')\n",
    "for index, row in df.iterrows():\n",
    "    #TODO: DELETE\n",
    "    if row['project'] == 'ant-ivy':\n",
    "        continue\n",
    "    repo = Repo.clone_from(row['url'], row['project'])\n",
    "    \n",
    "    # create key value pairs: key - release number, value - release tag (for git checkout purpose)\n",
    "    releases_number = row['releases'].split(', ')\n",
    "    releases_tags = row['releases_tags'].split(', ')\n",
    "    releases_dict = dict(zip(releases_number, releases_tags))\n",
    "    \n",
    "    for release in releases_dict:\n",
    "        release_tag = releases_dict[release]\n",
    "        repo.git.checkout(release_tag)\n",
    "        \n",
    "        print(\"extracting bug fixing files using OpenSZZ from repository: \" + row['project'] + \" at release \" + release)\n",
    "        subprocess.call(['java', '-jar', 'openszz.jar', '-all', row['url'], row['jira'], row['key']])\n",
    "        print(\"extraction done\")\n",
    "        output_file_name = row['key'] + '_BugInducingCommits.csv'\n",
    "        \n",
    "        if os.path.isfile(output_file_name):\n",
    "            \n",
    "            # 1. extracte bug fixing files\n",
    "            df1 = pd.read_csv(output_file_name, sep=';')\n",
    "            # key - bug fixing file, value: information on the bug fix\n",
    "            bug_fixing_file_dict = dict()\n",
    "            for index, row1 in df1.iterrows():\n",
    "                if row1[\"issueType\"] == \"Bug\":\n",
    "                    bug_fixing_file = row1[\"bugFixingfileChanged\"]\n",
    "                    bug_fixing_info = {\n",
    "                        \"bugfix_commit\": row1[\"bugFixingId\"],\n",
    "                        \"bugfix_commit_date\": row1[\"bugFixingTs\"],\n",
    "                        \"type\": row1[\"issueType\"]\n",
    "                    }\n",
    "                    if bug_fixing_file in bug_fixing_file_dict:\n",
    "                        bug_fixing_file_dict[bug_fixing_file].append(bug_fixing_info)\n",
    "                    else:\n",
    "                        bug_fixing_file_dict[bug_fixing_file] = [bug_fixing_info]\n",
    "                        \n",
    "            # 2. save bug fixing files as JSON in same format as manual validated data\n",
    "            json_file_name = row[\"project\"] + \"-\" + release + \"_bug_fixes.json\"\n",
    "            json_file = open(\"./release-level-data/\" + json_file_name, \"r\")\n",
    "            data = json.load(json_file)\n",
    "            json_file.close()\n",
    "            \n",
    "            for line in data:\n",
    "                line['bug_fixes'] = []\n",
    "                if line['file'] in bug_fixing_file_dict:\n",
    "                    line['bug_fixes'] = bug_fixing_file_dict[line['file']]\n",
    "            \n",
    "            with open(\"./release-level-data-OpenSZZ/\" + json_file_name, \"w\") as outfile:\n",
    "                json.dump(data, outfile)\n",
    "            print(\"release level data generated with OpenSZZ for project\" + row['project'] + \" at release \" + release)\n",
    "                \n",
    "            # 3. clean up csv files generated by OpenSZZ\n",
    "            os.remove(row['project'] + \".txt\")\n",
    "            os.remove(row['key'] + \"-log.txt\")\n",
    "            \n",
    "            fileList = glob.glob(row['key'] + \"_*.csv\")\n",
    "            for filePath in fileList:\n",
    "                try:\n",
    "                    os.remove(filePath)\n",
    "                except:\n",
    "                    print(\"Error while deleting file : \", filePath)\n",
    "            \n",
    "        else:\n",
    "            print(\"ERROR: extracting bug fixing files using OpenSZZ failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d28fdb",
   "metadata": {},
   "source": [
    "# RQ1 - Fisher exact test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ee95d4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting traditional smells from repository: ant-ivy\n",
      "Traditional smells extracted for project:  ant-ivy\n",
      "\n",
      "\n",
      "Fisher exact test odds ratio: 3.5230\n",
      "Fisher exact test p-value: 0.0515\n"
     ]
    }
   ],
   "source": [
    "from git import Repo\n",
    "import json\n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "# clone repo\n",
    "# repo = Repo.clone_from('https://github.com/apache/ant-ivy', 'ant-ivy')\n",
    "repo = Repo('ant-ivy')\n",
    "\n",
    "# checkout to specific release\n",
    "# print(repo.tags)\n",
    "repo.git.checkout('1.4.1')\n",
    "\n",
    "smelly_classes = extract_traditional_smells2('ant-ivy')\n",
    "# print(smelly_classes)\n",
    "\n",
    "# number of classes with at least one fixing and with at least one anti-pattern \n",
    "w_fix_w_anti = 0\n",
    "# number of classes with at least one fixing and without any anti-patterns\n",
    "w_fix_wo_anti = 0\n",
    "# number of classes without any fixing and with at least one anti-pattern \n",
    "wo_fix_w_anti = 0\n",
    "# number of classes without any fixing and without any anti-patterns\n",
    "wo_fix_wo_anti = 0\n",
    "\n",
    "f = open('./release-level-data/ant-ivy-1.4.1_bug_fixes.json')\n",
    "data = json.load(f)\n",
    "for line in data:\n",
    "    filename = line['file'].split(\"/\")[-1].split(\".\")[0]\n",
    "    if line['bug_fixes']:\n",
    "        if filename in smelly_classes:\n",
    "            w_fix_w_anti +=1\n",
    "        else:\n",
    "            w_fix_wo_anti += 1\n",
    "    else:\n",
    "        if filename in smelly_classes:\n",
    "            wo_fix_w_anti +=1\n",
    "        else:\n",
    "            wo_fix_wo_anti += 1\n",
    "\n",
    "f.close()\n",
    "\n",
    "# computer fisher exact test\n",
    "data = [[w_fix_w_anti, wo_fix_w_anti],\n",
    "         [w_fix_wo_anti, wo_fix_wo_anti]]\n",
    "\n",
    "oddsratio, pvalue = fisher_exact(data)\n",
    "print('\\n')\n",
    "print('Fisher exact test odds ratio: {:.4f}'.format(oddsratio))\n",
    "print('Fisher exact test p-value: {:.4f}'.format(pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cddfe9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
